{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f26876d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"True\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45c35024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<groq.resources.chat.completions.Completions object at 0x0000020CE4833890> async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000020CE51E8EF0> model_name='llama-3.3-70b-versatile' temperature=0.5 model_kwargs={} groq_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq \n",
    "llm = ChatGroq(api_key=os.environ[\"GROQ_API_KEY\"],model=\"llama-3.3-70b-versatile\",temperature=0.5)\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef56bd80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Generative AI refers to a type of artificial intelligence that is capable of generating new, original content, such as images, videos, music, text, or even entire datasets. This is in contrast to traditional AI, which is typically used for classification, regression, or other tasks that involve processing and analyzing existing data.\\n\\nGenerative AI uses complex algorithms, such as neural networks, to learn patterns and relationships in data, and then generates new data that is similar in style, structure, or content to the training data. The goal of generative AI is to create new, synthetic data that is indistinguishable from real data, or to generate data that is novel and innovative.\\n\\nSome common applications of generative AI include:\\n\\n1. **Image and video generation**: Generative AI can be used to generate realistic images and videos, such as faces, objects, or scenes.\\n2. **Text generation**: Generative AI can be used to generate text, such as articles, stories, or chatbot responses.\\n3. **Music generation**: Generative AI can be used to generate music, such as melodies, harmonies, or entire compositions.\\n4. **Data augmentation**: Generative AI can be used to generate new data that can be used to augment existing datasets, such as generating new images of objects from different angles or with different lighting conditions.\\n5. **Art and design**: Generative AI can be used to generate original artwork, such as paintings, sculptures, or architectural designs.\\n\\nSome of the key techniques used in generative AI include:\\n\\n1. **Generative Adversarial Networks (GANs)**: GANs consist of two neural networks that compete with each other to generate new data.\\n2. **Variational Autoencoders (VAEs)**: VAEs are neural networks that learn to compress and reconstruct data, and can be used to generate new data.\\n3. **Recurrent Neural Networks (RNNs)**: RNNs are neural networks that are well-suited for sequential data, such as text or music.\\n\\nGenerative AI has many potential applications, including:\\n\\n1. **Creative industries**: Generative AI can be used to generate new ideas, concepts, or content for creative industries such as art, music, or writing.\\n2. **Data science**: Generative AI can be used to generate new data for data science applications, such as data augmentation or synthetic data generation.\\n3. **Robotics and computer vision**: Generative AI can be used to generate new data for robotics and computer vision applications, such as generating new images of objects or scenes.\\n4. **Healthcare**: Generative AI can be used to generate new data for healthcare applications, such as generating new medical images or patient data.\\n\\nHowever, generative AI also raises important questions and challenges, such as:\\n\\n1. **Ethics**: Generative AI raises important ethical questions, such as the potential for generating fake or misleading content.\\n2. **Intellectual property**: Generative AI raises important questions about intellectual property, such as who owns the rights to generated content.\\n3. **Bias and fairness**: Generative AI can perpetuate biases and unfairness if the training data is biased or unfair.\\n\\nOverall, generative AI is a rapidly evolving field with many potential applications and challenges. As the technology continues to advance, it is likely to have a significant impact on many areas of society and industry.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 684, 'prompt_tokens': 41, 'total_tokens': 725, 'completion_time': 2.487272727, 'prompt_time': 0.001965232, 'queue_time': 0.059302943000000004, 'total_time': 2.489237959}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_3f3b593e33', 'finish_reason': 'stop', 'logprobs': None}, id='run--fe952295-e3b2-4cd9-a41d-c9e9e31aea5a-0', usage_metadata={'input_tokens': 41, 'output_tokens': 684, 'total_tokens': 725})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is generative AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f925daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an Expert AI Engineer,provide me answers based on the questions.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chat prompt template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an Expert AI Engineer,provide me answers based on the questions.\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f36be3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"**Langsmith Overview**\\n=======================\\n\\nLangsmith is an AI-powered language model designed to generate human-like text based on a given prompt or input. It is a type of large language model (LLM) that uses natural language processing (NLP) and machine learning algorithms to understand and generate text.\\n\\n**Key Features of Langsmith**\\n-----------------------------\\n\\n* **Text Generation**: Langsmith can generate text in various styles, including articles, stories, conversations, and more.\\n* **Language Understanding**: Langsmith has the ability to comprehend and interpret human language, including nuances and context.\\n* **Customization**: Langsmith can be fine-tuned for specific tasks and domains, allowing users to adapt the model to their needs.\\n* **Conversational Interface**: Langsmith can engage in conversations, responding to questions and statements in a human-like manner.\\n\\n**Technical Details**\\n--------------------\\n\\n* **Model Architecture**: Langsmith is built using a transformer-based architecture, which is a type of neural network designed for NLP tasks.\\n* **Training Data**: Langsmith is trained on a massive dataset of text from various sources, including books, articles, and websites.\\n* **Model Size**: Langsmith is a large model, with hundreds of millions of parameters, which allows it to learn complex patterns and relationships in language.\\n\\n**Use Cases for Langsmith**\\n---------------------------\\n\\n* **Content Generation**: Langsmith can be used to generate content, such as articles, blog posts, and social media posts.\\n* **Chatbots and Virtual Assistants**: Langsmith can be used to power chatbots and virtual assistants, providing human-like responses to user queries.\\n* **Language Translation**: Langsmith can be used to translate text from one language to another, with high accuracy and fluency.\\n* **Text Summarization**: Langsmith can be used to summarize long pieces of text, extracting key points and main ideas.\\n\\n**Limitations and Future Directions**\\n--------------------------------------\\n\\n* **Bias and Fairness**: Langsmith, like other LLMs, can perpetuate biases and stereotypes present in the training data.\\n* **Explainability**: Langsmith's decision-making process can be difficult to understand and interpret.\\n* **Future Directions**: Future research directions for Langsmith include improving its ability to understand and generate text in multiple languages, as well as developing more advanced conversational interfaces.\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 470, 'prompt_tokens': 58, 'total_tokens': 528, 'completion_time': 1.709090909, 'prompt_time': 0.002896683, 'queue_time': 0.055298132, 'total_time': 1.7119875919999998}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_3f3b593e33', 'finish_reason': 'stop', 'logprobs': None} id='run--f02b5bfc-1940-433b-b03f-47033c81e032-0' usage_metadata={'input_tokens': 58, 'output_tokens': 470, 'total_tokens': 528}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt|llm\n",
    "\n",
    "response = chain.invoke({\"input\":\"Can you tell me about langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6059bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  stroutput Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "outputParser = StrOutputParser()\n",
    "chain = prompt|llm|outputParser\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
